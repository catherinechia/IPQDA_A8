{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(perHyperstack_in_progress)_Cellpose_for_A8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run Cellpose 2.0 for IPQDA assignment 8 using Colab with GPU\n",
        "\n",
        "Author: Catherine Chia\n",
        "\n",
        "Date: 2022-06-20\n",
        "\n",
        "Real authors: Carsen Stringer, Marius Pachitariu, Pradeep Rajasekhar, Jacquemet lab, and Henriques lab. \n",
        "\n",
        "References:\n",
        "https://colab.research.google.com/github/MouseLand/cellpose/blob/main/notebooks/run_cellpose_2.ipynb\n",
        "\n",
        "https://colab.research.google.com/github/MouseLand/cellpose/blob/main/notebooks/Cellpose_cell_segmentation_2D_prediction_only.ipynb\n",
        "\n",
        "https://cellpose.readthedocs.io/en/latest/\n"
      ],
      "metadata": {
        "id": "MScP_XCkk2DK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "LmNkjnlumUw2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "942_KKyWko8K",
        "outputId": "0be200d4-3b63-49da-bdb6-e75a297483bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cellpose\n",
            "  Downloading cellpose-2.0.5-py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from cellpose) (4.64.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (from cellpose) (5.5.0)\n",
            "Collecting numba>=0.53.0\n",
            "  Downloading numba-0.55.2-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 63.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: llvmlite in /usr/local/lib/python3.7/dist-packages (from cellpose) (0.34.0)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (from cellpose) (2021.11.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from cellpose) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from cellpose) (1.11.0+cu113)\n",
            "Collecting fastremap\n",
            "  Downloading fastremap-1.13.0-cp37-cp37m-manylinux2010_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 43.2 MB/s \n",
            "\u001b[?25hCollecting imagecodecs\n",
            "  Downloading imagecodecs-2021.11.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.0 MB 101.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cellpose) (1.4.1)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 62 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.53.0->cellpose) (57.4.0)\n",
            "Collecting llvmlite\n",
            "  Downloading llvmlite-0.38.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 19 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->cellpose) (4.1.1)\n",
            "Installing collected packages: llvmlite, opencv-python-headless, numba, imagecodecs, fastremap, cellpose\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed cellpose-2.0.5 fastremap-1.13.0 imagecodecs-2021.11.20 llvmlite-0.38.1 numba-0.55.2 opencv-python-headless-4.6.0.66\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python-headless<4.3\n",
            "  Downloading opencv_python_headless-4.2.0.34-cp37-cp37m-manylinux1_x86_64.whl (21.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.6 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless<4.3) (1.21.6)\n",
            "Installing collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.6.0.66\n",
            "    Uninstalling opencv-python-headless-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-headless-4.6.0.66\n",
            "Successfully installed opencv-python-headless-4.2.0.34\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "Mon Jun 20 16:57:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            ">>> GPU activated? YES\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#Setup\n",
        "!pip install cellpose\n",
        "!pip install torch torchvision torchaudio #from2D\n",
        "!pip install \"opencv-python-headless<4.3\"\n",
        "\n",
        "#Other libraries\n",
        "import numpy as np\n",
        "import time, os, sys, random\n",
        "from urllib.parse import urlparse\n",
        "import skimage.io\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "mpl.rcParams['figure.dpi'] = 300\n",
        "from urllib.parse import urlparse\n",
        "import shutil\n",
        "\n",
        "#GPU \n",
        "!nvcc --version\n",
        "!nvidia-smi\n",
        "\n",
        "import os, shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from cellpose import core, utils, io, models, metrics\n",
        "from glob import glob\n",
        "\n",
        "use_GPU = core.use_gpu()\n",
        "yn = ['NO', 'YES']\n",
        "print(f'>>> GPU activated? {yn[use_GPU]}')\n",
        "\n",
        "\n",
        "#Mount Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#from tifffile import imread, imsave\n",
        "\n",
        "#https://stackoverflow.com/questions/8924173/how-do-i-print-bold-text-in-python\n",
        "BOLD = '\\033[1m'\n",
        "UNDERLINE = '\\033[4m'\n",
        "END = '\\033[0m'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Images to segment"
      ],
      "metadata": {
        "id": "wuBA_7xIbemY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Step 4: Enter Directory path containing the image(s): \n",
        "#@markdown ##### Existing Masks directory will be deleted. (Does not read images in subfolders)\n",
        "Input_Directory = \"/content/gdrive/MyDrive/_Shared/20220617_IPQDA_A8/data/perHyperstack\" #@param {type:\"string\"}\n",
        "dir = Input_Directory #TODO: To remove\n",
        "input_dir = os.path.join(Input_Directory, \"\") #adds separator to the end regardless if path has it or not\n",
        "\n",
        "#@markdown ###Optional: Enter image extension here to read only files/images of specified extension (.tif,.jpg..): \n",
        "#@markdown ###### Leave empty if not specifying anything\n",
        "image_format = \"tif\" #@param {type:\"string\"}\n",
        "\n",
        "##@markdown ###Tick if image is RGB: \n",
        "#RGB= False #@param {type:\"boolean\"}\n",
        "#rgb=RGB\n",
        "save_dir = input_dir+\"Masks/\"\n",
        "if not os.path.exists(save_dir):\n",
        "  os.makedirs(save_dir)\n",
        "else:\n",
        "  print(\"Existing Mask Directory found. Deleting it.\")\n",
        "  shutil.rmtree(save_dir)\n",
        "\n",
        "#@markdown ##### Save Directory will be created in the input path under Masks\n",
        "\n",
        "##@markdown ###Advanced Parameters\n",
        "#Use_Default_Advanced_Parameters = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# r=root, d=directories, f = files\n",
        "files=[] #store all files\n",
        "\n",
        "for r, d, f in os.walk(input_dir):\n",
        "    for fil in f:\n",
        "      if (image_format):\n",
        "        if fil.endswith(image_format):\n",
        "          files.append(os.path.join(r, fil))\n",
        "      else:\n",
        "        files.append(os.path.join(r, fil))\n",
        "    break #only read the root directory; can change this to include levels\n",
        "if(len(files)==0):\n",
        "  print(\"Number of images loaded: %d.\" %(len(files)))\n",
        "  print(\"Cannot read image files. Check if folder has images\")\n",
        "else:\n",
        "  print(\"Number of images loaded: %d.\" %(len(files)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "code",
        "id": "dvM6pTfrbd_F",
        "outputId": "82afe9fe-bbee-41da-d70a-b8a0498cdc8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images loaded: 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download pre-trained models"
      ],
      "metadata": {
        "id": "uvNpFRdRmPiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Downloading Models\")\n",
        "from cellpose import models,core\n",
        "\n",
        "print(\"*************************************************\")\n",
        "print(\"Libraries imported and configured\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG0_tLcimSX3",
        "outputId": "be3c8600-6b7d-4105-e1b1-40f00898bd2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Models\n",
            "*************************************************\n",
            "Libraries imported and configured\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select a model (e.g. cyto, nicknamed Cytoplasm)"
      ],
      "metadata": {
        "id": "t99730MVnbIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Pre-trained model:\n",
        "Model_Choice = \"Cytoplasm\" #@param [\"Cytoplasm\",\"Cytoplasm2\", \"Cytoplasm2_Omnipose\", \"Bacteria_Omnipose\", \"Nuclei\"]\n",
        "model_choice=Model_Choice\n",
        "\n",
        "print(\"Using model \",model_choice)\n",
        "\n",
        "#@markdown ###Channel Parameters:\n",
        "Channel_to_use_for_segmentation = \"Green\" #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
        "\n",
        "#@markdown If you have a secondary channel that can be used, for instance nuclei, choose it here:\n",
        "Use_nuclear_channel= True #@param {type:\"boolean\"}\n",
        "# Nuclear_channel=\"1\" #@param[1,2,3]\n",
        "Second_segmentation_channel= \"Red\" #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
        "\n",
        "\n",
        "\n",
        "#########################\n",
        "# Some background work\n",
        "# Here we match the choice of model to its original/true label\n",
        "if model_choice==\"Cytoplasm\":\n",
        "  model_type=\"cyto\"\n",
        "\n",
        "elif model_choice==\"Cytoplasm2\":\n",
        "  model_type=\"cyto2\"\n",
        "\n",
        "elif model_choice==\"Cytoplasm2_Omnipose\":\n",
        "  model_type=\"cyto2_omni\"\n",
        "\n",
        "elif model_choice==\"Bacteria_Omnipose\":\n",
        "  model_type=\"bact_omni\" \n",
        "  diameter = 0\n",
        "\n",
        "elif model_choice==\"Nuclei\":\n",
        "  model_type=\"nuclei\" \n",
        "\n",
        "\n",
        "# Here we match the channel to number\n",
        "if Channel_to_use_for_segmentation == \"Grayscale\":\n",
        "  Channel_for_segmentation = 0\n",
        "elif Channel_to_use_for_segmentation == \"Blue\":\n",
        "  Channel_for_segmentation = 3\n",
        "elif Channel_to_use_for_segmentation == \"Green\":\n",
        "  Channel_for_segmentation = 2\n",
        "elif Channel_to_use_for_segmentation == \"Red\":\n",
        "  Channel_for_segmentation = 1\n",
        "\n",
        "segment_channel=int(Channel_for_segmentation)\n",
        "\n",
        "if Second_segmentation_channel == \"Blue\":\n",
        "  Nuclear_channel = 3\n",
        "elif Second_segmentation_channel == \"Green\":\n",
        "  Nuclear_channel = 2\n",
        "elif Second_segmentation_channel == \"Red\":\n",
        "  Nuclear_channel = 1\n",
        "elif Second_segmentation_channel == \"None\":\n",
        "  Nuclear_channel = 0\n",
        "\n",
        "nuclear_channel=int(Nuclear_channel)\n",
        "\n",
        "\n",
        "# #@markdown If the image has only one channel, leave it as 0\n",
        "# Channel_for_segmentation=\"2\" #@param[0,1,2,3]\n",
        "\n",
        "# channels = [cytoplasm, nucleus]\n",
        "if model_choice not in \"Nuclei\":\n",
        "  if Use_nuclear_channel:\n",
        "    channels=[segment_channel,nuclear_channel]\n",
        "  else:\n",
        "    channels=[segment_channel,0]\n",
        "else: #nucleus\n",
        "  channels=[segment_channel,0]\n",
        "\n",
        "\n",
        "# DEFINE CELLPOSE MODEL\n",
        "# model_type='cyto' or model_type='nuclei'\n",
        "#model = models.Cellpose(gpu=use_GPU, model_type=model_type, omni = omni)\n",
        "model = models.Cellpose(gpu=use_GPU, model_type=model_type)\n",
        "\n",
        "\n",
        "\n",
        "# define CHANNELS to run segementation on\n",
        "# grayscale=0, R=1, G=2, B=3\n",
        "# channels = [cytoplasm, nucleus]\n",
        "# if NUCLEUS channel does not exist, set the second channel to 0\n",
        "# channels = [0,0]\n",
        "# IF ALL YOUR IMAGES ARE THE SAME TYPE, you can give a list with 2 elements\n",
        "# channels = [0,0] # IF YOU HAVE GRAYSCALE\n",
        "# channels = [2,3] # IF YOU HAVE G=cytoplasm and B=nucleus\n",
        "# channels = [2,1] # IF YOU HAVE G=cytoplasm and R=nucleus\n",
        "\n",
        "# or if you have different types of channels in each image\n",
        "#channels = [[2,3], [0,0], [0,0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "code",
        "id": "WUEYJbZinSwA",
        "outputId": "38a349f6-d0c9-4974-9f5c-e8fbeaee8ed0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using model  Cytoplasm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25.3M/25.3M [00:00<00:00, 85.7MB/s]\n",
            "100%|██████████| 5.23k/5.23k [00:00<00:00, 6.24MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "VGy2x3Ipnqqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Segmentation parameters:\n",
        "\n",
        "#@markdown diameter of cells (set to zero to use diameter from training set):\n",
        "diameter =  30 #@param {type:\"number\"}\n",
        "#@markdown threshold on flow error to accept a mask (set higher to get more cells, e.g. in range from (0.1, 3.0), OR set to 0.0 to turn off so no cells discarded):\n",
        "flow_threshold = 0.4 #@param {type:\"slider\", min:0.0, max:3.0, step:0.1}\n",
        "#@markdown threshold on cellprob output to seed cell masks (set lower to include more pixels or higher to include fewer, e.g. in range from (-6, 6)):\n",
        "cellprob_threshold=0 #@param {type:\"slider\", min:-6, max:6, step:1}\n",
        "\n",
        "# if diameter is set to None, the size of the cells is estimated on a per image basis\n",
        "# you can set the average cell `diameter` in pixels yourself (recommended) \n",
        "# diameter can be a list or a single number for all images\n",
        "if diameter is 0:\n",
        "  diameter = None\n",
        "  print(\"Diameter is set to None. The size of the cells will be estimated on a per image basis\")\n",
        "\n",
        "\n",
        "#TODO: omnipose\n",
        "# # @markdown ###If cells are elongated or have branches, tick this. It will use omnipose\n",
        "\n",
        "# omni= False #@param {type:\"boolean\"}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "code",
        "id": "tRNDkAqYnsEj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess images to a format that Cellpose is happy with.\n",
        "\n",
        "Multiplane images should be of shape nplanes x channels x nY x nX, or \n",
        "as nplanes x nY x nX.\n",
        "[https://cellpose.readthedocs.io/en/latest/inputs.html]"
      ],
      "metadata": {
        "id": "q_T6ClhqoYEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gets image files in dir (ignoring image files ending in _masks)\n",
        "imgs=[] #store all images\n",
        "\n",
        "#Read images \n",
        "for f in files:\n",
        "  im = skimage.io.imread(f)\n",
        "  n_dim = len(im.shape)     #shape of image\n",
        "  dim = im.shape            #dimension of image\n",
        "  id_channel = min(dim)     #channel will be dimension with min value usually\n",
        "  channel_position = dim.index(id_channel)\n",
        "\n",
        "  \n",
        "  # print(n_dim)\n",
        "  # print(dim)\n",
        "  # print(channel_position)\n",
        "\n",
        "  #if number of dim is 3 and id_channel is first index, swap channel to last indx\n",
        "  if n_dim == 3 and channel_position == 0:\n",
        "    im = im.transpose (1,2,0)\n",
        "    dim = im.shape\n",
        "    \n",
        "  \n",
        "  #specifically for IPQDA A8 because the dataset is of dim = (27, 1024, 1024, 3)\n",
        "  if n_dim == 4 and channel_position == 3:\n",
        "    im = np.transpose(im, (0,3,1,2))\n",
        "\n",
        "    #Update dimensions\n",
        "    n_dim = len(im.shape)     #shape of image\n",
        "    dim = im.shape            #dimension of image\n",
        "    id_channel = min(dim)     #channel will be dimension with min value usually\n",
        "    channel_position = dim.index(id_channel)\n",
        "\n",
        "    print(\"Shape changed\")\n",
        "    print(\"Shape of image: \" + str(n_dim))\n",
        "    print(\"Dimension of image: \" + str(dim))\n",
        "    print(\"Channel position: \" + str(channel_position))\n",
        "\n",
        "  imgs.append(im)\n",
        "  \n",
        "\n",
        "nimg = len(imgs)\n",
        "print(\"No of images loaded are: \", nimg)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsqYYIXuotkq",
        "outputId": "3b97f02d-5ea2-4b5c-dc05-aabcad0db82b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape changed\n",
            "Shape of image: 4\n",
            "Dimension of image: (27, 3, 1024, 1024)\n",
            "Channel position: 1\n",
            "No of images loaded are:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run selected Cellpose model to image(s) to segment cells\n",
        "\n",
        "Save output:\n",
        "1.   *_seg.npy (segmentation in numpy array)\n",
        "2.   *masks.tiff (masks)\n",
        "3. Save parameters in *.txt "
      ],
      "metadata": {
        "id": "az6R9KyHiApS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through image list\n",
        "masks=[] #stores all masks\n",
        "flows=[] #stores all flows\n",
        "segs =[] #stores all segs\n",
        "\n",
        "for img_idx, img in enumerate(imgs):\n",
        "    file_name=os.path.splitext(os.path.basename(files[img_idx]))[0]\n",
        "    print(\"\\nSegmenting: \",file_name)\n",
        "\n",
        "    mask, flow, style, diam = model.eval(\n",
        "        img, diameter=diameter, \n",
        "        flow_threshold=flow_threshold,\n",
        "        cellprob_threshold=cellprob_threshold, \n",
        "        channels=channels,\n",
        "        do_3D=True)\n",
        "    \n",
        "    #save images in folder with the diameter value used in cellpose\n",
        "    print(\"Segmentation complete . Saving Masks, Flows and Segs\")\n",
        "    \n",
        "    #SAVING MASK\n",
        "    ##mask_output_name=save_dir+\"MASK_\"+file_name+\".tif\"\n",
        "    mask_output_name=save_dir+file_name+\"_cp_masks.tif\" #corrected for IPQDA assignment 8\n",
        "   \n",
        "    #Save mask as 16-bit in case this has to be used for detecting than 255 objects\n",
        "    mask=mask.astype(np.uint16)\n",
        "    skimage.io.imsave(mask_output_name,mask, check_contrast=False)\n",
        "\n",
        "    masks.append(mask)\n",
        "    \n",
        "    #SAVING FLOWS\n",
        "    #flow_output_name=flows_save_dir+\"FLOWS_\"+file_name+\".tif\"\n",
        "    flow_output_name=save_dir+file_name+\"_cp_flows.tif\"\n",
        "\n",
        "    #Save as 8-bit\n",
        "    flow_image=flow[0].astype(np.uint8)\n",
        "    skimage.io.imsave(flow_output_name,flow_image, check_contrast=False)\n",
        "\n",
        "    flows.append(flow)\n",
        "\n",
        "    #SAVING SEGMENTATIONS\n",
        "    #cellpose.io\n",
        "    seg_output_name = save_dir + file_name + \"_seg.npy\"\n",
        "    seg = io.masks_flows_to_seg(img, \n",
        "                          mask, \n",
        "                          flow, \n",
        "                          diam, \n",
        "                          seg_output_name, \n",
        "                          channels)\n",
        "    segs.append(seg)\n",
        "\n",
        "\n",
        "#Save parameters used in Cellpose\n",
        "parameters_file=save_dir+\"Cellpose_parameters_used.txt\" \n",
        "outFile=open(parameters_file, \"w\") \n",
        "outFile.write(\"CELLPOSE PARAMETERS\\n\") \n",
        "outFile.write(\"Model: \"+model_choice+\"\\n\") \n",
        "if diameter == 0:\n",
        "  diameter = \"Automatically estimated by cellpose\"\n",
        "#outFile.write(\"Omni Flag: \"+str(omni)+\"\\n\") \n",
        "outFile.write(\"Diameter: \"+str(diameter)+\"\\n\") \n",
        "outFile.write(\"Flow Threshold: \"+str(flow_threshold)+\"\\n\") \n",
        "outFile.write(\"Cell probability Threshold: \"+str(cellprob_threshold)+\"\\n\") \n",
        "outFile.close() \n",
        "print(\"\\nSegmentation complete and files saved\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "code",
        "id": "JWbDBywNhx2q",
        "outputId": "e210079b-544b-4866-cc29-073796764476"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Segmenting:  KTRed\n",
            "Segmentation complete . Saving Masks, Flows and Segs\n",
            "\n",
            "Segmentation complete and files saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot cellprob, gradXY and gradZ...\n",
        "\n",
        "...nah, I give up here. \n",
        "\n",
        "I will install Cellpose to view the generated *_seg.npy and all other files. "
      ],
      "metadata": {
        "id": "5CgKRcW78nnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # DISPLAY RESULTS\n",
        "# from cellpose import plot, utils, io\n",
        "\n",
        "# nimg = len(imgs)\n",
        "# for idx in range(nimg):\n",
        "#     maski = masks[idx]\n",
        "#     flowi = flows[idx][0]\n",
        "\n",
        "#     fig = plt.figure(figsize=(12,5))\n",
        "#     plot.show_segmentation(fig, imgs[idx], maski, flowi, channels=channels[idx])\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "IBH3BNN38sKH",
        "outputId": "ef4ab82c-6215-4b64-fffb-321e786b765e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-eaa18195e7db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_segmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaski\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflowi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/cellpose/plot.py\u001b[0m in \u001b[0;36mshow_segmentation\u001b[0;34m(fig, img, maski, flowi, channels, file_name)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m50.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mimg0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'original image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (27, 3, 1024, 1024) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**How to extract the ROIs from the mask or label maps using FIJI**\n",
        "\n",
        "The masks will be saved as a 16-bit label image, where each cell/ROI is a different colour or label. If you are using ImageJ/FIJI and want to convert this to ROIs for the ROI Manager, there are a few options to convert into ROIs:\n",
        "\n",
        "\n",
        "*   SCF plugin (Update site:\thttps://sites.imagej.net/SCF-MPI-CBG/). After [installing the plugin](https://imagej.net/How_to_follow_a_3rd_party_update_site), go to SCF-> Segmentation -> LabelMap to ROI Manager (2D). This should generate the ROIs in ROI Manager\n",
        "\n",
        "*   Another really nice plugin: [LabelsToROIs](https://github.com/ariel-waisman/LabelsToROis). It has some nice features to adjust the size of the ROIs and generate measurements  "
      ],
      "metadata": {
        "id": "aS8Eb20lkJyR"
      }
    }
  ]
}